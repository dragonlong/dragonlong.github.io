---
layout: post
title: Visual reasoning
date: 2018-10-10
---
![My helpful screenshot]({{ "/assets/self.JPG" | absolute_url }})

* higher level CV challenges, intuition;
Visual question answering:
Relate the, what shape is followed;
Neural Module Networks(?)-require program annotations(?)

* the methodology and framework;
Image--> Scene Parsing--> Symbolic Representations(4000 images with 30000 iterations for ) filter shape;
Program Generator/Executor(Something like robots)
Agent in Virtual Environment;(doing something that seems not useful, or even possible)
- Pre-train generator with question-program annotations;
- followed by joint training with Executor with RL(?) and GT question answer annotations
- I want to generate, but I don't want to look at the image;
let's keep everything simple?
Given the question, I'll first reason about the visual cues based on my question or sentence, but it seems to be separable, we could just first get an explicit Structural Scene Representation, also we get
bi-directional LSTM for question parsing.

* Practice, Examples, advantages and limitations;

* Limitations and New potential(New tendencies);
In order to solve the problems, instead of trying to train the whole stuff with time-consuming
training, we could using techniques like pre-training on a small annotated dataset;
