---
layout: default
title: Xiaolong, Vision
---
<!-- Services Section -->
<section id="services" class="services-section">
	  <div class="container">
		    <div class="row">
		      <h1 class="title">Publications</h1>
		    </div>
				<div class="row paper">
						<div class="col-sm-3">
							<img src="publications/pipeline.png" class="paper-fig img-responsive">
						</div>
						<div class="col-sm-8 col-sm-offset-1">
								<h4 class="text-left">Automatic Image Grading for Diabetic Retinopathy(DR) and Diabetic Macular Edema(DME)</h4>
								<p class="text-left">
									<span class="label label-success">Supervised Learning</span>
									<span class="label label-success">Boost</span>
									<span class="label label-success">feature blending</span>
									<span class="label label-success">ROI Localization</span>
								</p>
								<p class="text-left">Junyan Wu, <strong>Xiaolong LI</strong>, Ting Zhou, Yu Wang</p>
								<p class="text-left">Part of Joint Paper to ISBI 2018</p>
								<div class="text-left btns">
									<a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
					 						title="Abstract" data-content="Diabetes mellitus is one of leading cause of vision loss globally.
																										Diabates increase the risk of a range of eye diseases,
																										but the main cause of blindness associated with diabates is
																										diabetic retinopathy(DR). Diabetic Macular Edema(DME) is
																										a complication associated with DR of which retinal thickening
																										or accumulation of fluid can occur at any stage. Early
																										detection for DR and DME is important to save the vision of
																										diabetes patients. In this paper, we propose an ensemble pipline
																										which combines convolutional neural network and feature
																										blending for automatically predicting the DR and DME
																										severity scores. It outperforms the usual end-to-end convolutional
																										neural network method.">Abstract</a>
																										<a class="btn btn-default btn-xs disabled" href="publications/automatic-image-grading.pdf">PDF</a>
																										<a class="btn btn-default btn-xs disabled" href="https://github.com/dragonlong/DR_blend">Project</a>
								</div>
							</div>
						</div>
						<div class="row paper">
								<div class="col-sm-3">
									<img src="publications/tie.jpg" class="paper-fig img-responsive">
								</div>
								<div class="col-sm-8 col-sm-offset-1">
										<h4 class="text-left">Texture orientation-resolving imaging with structure illumination</h4>
										<p class="text-left">
											<span class="label label-success">Optical Imaging</span>
											<span class="label label-success">Fourier Analysis</span>
										</p>
										<p class="text-left">Ziling Wu, <strong>Xiaolong LI</strong>, Yunhui Zhu</p>
										<p class="text-left">2017 SPIE, Computational Imaging II</p>
										<div class="text-left btns">
											<a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
							 						title="Abstract" data-content="ssss">Abstract</a>
																												<a class="btn btn-default btn-xs disabled" target="_blank" href="https://dragonlong.github.io/">PDF</a>
																												<a class="btn btn-default btn-xs disabled" target="_blank" href="https://dragonlong.github.io/">Project</a>
										</div>
									</div>
								</div>
								<div class="row paper">
										<div class="col-sm-3">
											<img src="publications/tsp.png" class="paper-fig img-responsive">
										</div>
										<div class="col-sm-8 col-sm-offset-1">
												<h4 class="text-left">Research on solving Traveling Salesman Problem based on virtual instrument technology and genetic-annealing algorithms.</h4>
												<p class="text-left">
													<span class="label label-success">Optimization</span>
													<span class="label label-success">Genetic-annealing</span>
												</p>
												<p class="text-left">Muhao Chen, Chen Gong <strong>Xiaolong LI</strong>, Zongxin Yu</p>
												<p class="text-left">2015 Chinese Automation Congress, CAC</p>
												<div class="text-left btns">
													<a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
									 						title="Abstract" data-content="od.">Abstract</a>
																												<a class="btn btn-default btn-xs disabled" target="_blank" href="https://dragonlong.github.io/">PDF</a>
																												<a class="btn btn-default btn-xs disabled" target="_blank" href="https://dragonlong.github.io/">Project</a>
												</div>
											</div>
										</div>
					</div>
</section>

<section id="projects" class="project-solo">
<div>
	<h1 class="title">Projects on Robotics and Computer Vision, Image Processing</h1>
</div>
<div style="border: 1px solid green;">
	<h2> GAN for Sketches Auto-complete</h2>
	<p>
		<img src="projects/gan.png">
		Our project’s aim is to classify products using their images. We are comparing results from three classification techniques
Traditional Computer Vision Techniques - Bag of Words SIFT + SVM
Convolutional Neural Networks (CNN)
Transfer Learning (Pre-trained model)
	</p>
</div>
<div style="border: 1px solid green;">
	<h2> Recursive Bayesian Filtering
Practice for Robot Visual Search</h2>
	<p>
		<img src="projects/bayes.png">
		When the lost target’s location is not predictable or narrowly localized the sensor
needs to acquire new data to locate it. This new data can be obtained
by executing a time-optimized search, based on past data that the sensor has
collected. Recursive Bayesian Filtering (RBF) algorithms have been used to
generate the optimal search paths for various applications such as unmanned
aerial vehicles searching for a lost target at sea and camera mounted mobile
robots searching for a target [3, 4]. In this course project, I apply RBF to the
task of automatic visual search in man-made environment. A gaussian motion
model is used here, while also sensor-based observation model is adopted. I
use a novel particle filter with a priori target tracking information considered.
The simulation and experiment have shown this method has good robustness
when the target is lost in FOV. Further improvement and application are also
discussed.
	</p>
</div>
<div style="border: 1px solid green;">
	<h2> 3D Reconstruction based on Drone and Kinect</h2>
	<p>
		<img src="https://media.giphy.com/media/F3KQxoKYdTCJXs2Nv4/giphy.gif">
		Multi-rotor copter is a hot research and application field these years due to its excellent hover performance,
		easy to control, and small size for packing. In situations like autonomous surveillance, unmanned exploration,
		the aerial vehicles have such great application potential, some revolutionary cross innovation which are based
		on aerial vehicles have been already appearing in this world. With its small shape and excellent motion ability,
		the multi-rotor aerial vehicle is fit for those environment which is narrower or more complex when compared to others.
		However, in this time, since SLAM technology is now under research and optimization, including those hardware, the indoor
		navigation for aerial robots has just been realized in those advanced Labs or companies, the technology is at its start-up.
		Meanwhile, we should also notice that so many excellent algorithms are joining the open-source tendency, like the ORB-SLAM,
		RGBD-SLAM, and those flight control unit is more and more reliable, depth camera like Kinect becomes cheaper, so it is both
		affordable and meaningful to build such system by ourselves. On the one hand, it’s important to help those technologies about autonomous
		indoor navigation for aerial robots, on the other hand, it will realize the unmanned exploration for special environment with aerial vehicles.
		I explore the whole process to build such a SLAM system, also figure out the composition of software and hardware. This project implements SLAM
		algorithms from those cutting-edge Labs, while also achieves integration of different technologies in one system. This project achieves the first stage of
		real-time 3D reconstruction of indoor environment, which matters much for the transition of aerial vehicles to unmanned flying robots.
	</p>
</div>
</section>




<!--Google Analytics-->
<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
    a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'UA-100690611-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- jQuery -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
        integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Custom JavaScript -->
<script src="js/effect.js"></script>

<ul class="contacts">
	<li><a href="https://ece.vt.edu/">ECE Department, VT</a></li>
	<li><a href="https://sites.google.com/vt.edu/cvgroup">Group Project on Image Classification</a></li>
  <li><a href="http://weekly.hustnews.com/index/#word_news_id=8338&keyword=%u6700%u662F%u4E61%u6101&page=1">My love</a></li>
	</ul>
